---
title: Información suplementaria para el artículo "Generación de red hidrográfica densa de República Dominicana a partir de modelo digital de elevaciones de resolución media"
authors:
  - name: José-Ramón Martínez-Batlle\orcidlink{0000-0001-9924-0327}
    department: Facultad de Ciencias
    affiliation: Universidad Autónoma de Santo Domingo (UASD)
    location:  Santo Domingo, República Dominicana
    email: joseramon@geografiafisica.org
  - name: Michela Izzo Gioiosa\orcidlink{0000-0003-4835-3967}
    department: Directora Ejecutiva
    affiliation: Guakia Ambiente
    location:  Santo Domingo, República Dominicana
    email: michela.izzo@guakiambiente.org
abstract: |
  Enter the text of your abstract here.
keywords:
  - modelo digital de elevaciones
  - análisis hidrológico
  - Procesamiento de datos geoespaciales
  - hidrología computacional
bibliography: references.bib
csl: apa-es.csl
lang: es
output: rticles::arxiv_article
editor_options: 
  chunk_output_type: console
always_allow_html: true
header-includes:
  \usepackage{orcidlink}
  \usepackage{float}
  \renewcommand\tablename{Tabla}
  \renewcommand\figurename{Figura}
  \usepackage[all]{nowidow}
  \usepackage{xcolor}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = FALSE, 
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  out.width = '100%',
  # res = 300,
  dpi = 300)
# options(digits = 3)
```

## Suplemento para la sección Materiales y Métodos {.unnumbered}

### Obtención y Preprocesamiento del DEM

Los siguientes bloques de código cargan los paquetes de uso común a lo largo de este cuaderno, así como funciones creadas por nosotros para eficientizar las tareas de limpieza y representación de datos y mapas. Igualmente, aprovechamos este bloque de código para declarar la ruta del directorio donde se alojan los archivos fuente, la cual reaprovechamos en distintas partes del código.

```{r suphidropaquetes}
conflicted::conflict_prefer("select", "dplyr")
conflicted::conflict_prefer("filter", "dplyr")
library(raster)
library(sf)
library(kableExtra)
library(tidyverse)
library(gdalUtilities)
source('R/funciones.R')
dem_proc_dir <- 'alos-palsar-dem-rd/dem/'
```

```{r cargarfuentesotrormd, echo=F, include=F}
res_h3 <- 7 #Escribir un valor entre 4 y 7, ambos extremos inclusive
ruta_ez_gh <- 'https://raw.githubusercontent.com/geofis/zonal-statistics/'
ez_ver <- 'd7f79365168e688f0d78f521e53fbf2da19244ef/'
if(!any(grepl('^pais_url$', ls()))){
  pais_url <- paste0(ruta_ez_gh, ez_ver, 'inst/extdata/dr.gpkg')
  pais <- invisible(st_read(pais_url, optional = T, layer = 'pais', quiet = T))
  st_geometry(pais) <- "geometry"
  pais <- st_transform(pais, 32619)
}
```

Descargamos 42 escenas ALOS PALSAR RTC, específicamente los *Hi-Res Terrain Corrected*, desde el Centro de Archivo Activo Distribuido (DAAC) del [Alaska Satellite Facility (ASF)](https://asf.alaska.edu/) [@asfdaac2014hires], para posteriormente depurarlas y seleccionar las más idóneas para unirlas en un mosaico creado como ráster virtual. La descarga la realizamos por lotes, usando un *script* de Python provisto por el propio ASF.

```{python, eval=F}
python download-all-2023-04-20_00-30-00.py
```

> Al momento de realizarse esta investigación, la tendencia en el análisis de datos geoespaciales apuntaba hacia enfoques basados en la nube, como Google Earth Engine y Microsoft Planetary Computer. Nosotros usamos regulamente estas plataformas en nuestras investigaciones, pero ciertos algoritmos esenciales para el análisis hidrológico aún no se encuentran disponibles en estos servicios. Por esta razón, nos vimos en la necesidad de utilizar nuestros propios equipos informáticos (Intel(R) Core(TM) i7-7700K CPU \@ 4.20GHz, 64 GB de memoria RAM, unidad de estado sólido NVMe, corriendo bajo Ubuntu 20.04) y, aunque conseguimos paralelizar ciertos procesos, la mayoría de los algoritmos de hidrolología computacional no utilizan eficientemente los múltiples núcleos de los procesadores, resultando en una subutilización de la capacidad de memoria y en procesamientos más lentos que los que comúnmente se conseguirían en la nube.

Identificamos las escenas necesarias para cubrir íntegramente la República Dominicana, usando una búsqueda geográfica mediante polígono delimitador en ASF. Dado que la misión del ALOS-PALSAR ofrece escenas de distintas fechas para una misma área, las descargamos todas y posteriormente excluimos del análisis las redundantes, conservando siempre la más reciente. Utilizando el índice de huellas de escenas, escribimos un pequeño programa para seleccionar las más recientes allí donde hubiese redundancia. Con esto construimos un índice de DEM para guiarnos durante la construcción del ráster virtual.

```{r crearindice}
ind_orig <- invisible(
  st_read('alos-palsar-dem-rd/asf-datapool-results-2023-04-19_08-31-26.geojson',
          quiet = T)) %>% 
   rownames_to_column('fila') %>% mutate(fila = as.integer(fila))
distancias <- ind_orig %>% st_centroid() %>% st_distance() %>% units::drop_units()
distancias[upper.tri(distancias, diag = T)] <- NA
indices <- which(distancias < 1000, arr.ind = TRUE)
duplicados <- as.data.frame(indices) %>% 
  mutate(dup_id = 1:nrow(indices)) %>% 
  pivot_longer(-dup_id, names_to = 'tipo', values_to = 'fila') %>% 
  select(-tipo)
seleccionados <- duplicados %>%
  inner_join(ind_orig %>% select(fila, startTime) %>% st_drop_geometry) %>% 
  group_by(dup_id) %>% filter(startTime == max(startTime)) %>% pull(fila)
ind_orig_sel <- ind_orig %>%
  filter(!fila %in% duplicados$fila | fila %in% seleccionados) %>% 
  filter(centerLon < -72.1821)
```

```{r tablaindice}
ind_orig_sel %>% select(sceneName, startTime) %>% st_drop_geometry() %>%
  estilo_kable(titulo = paste('Escenas ALOS-PALSAR usadas para generar un DEM de 12.5 m de
                        resolución espacial de República Dominicana'))
```

En total, para cubrir el territorio de República Dominicana, necesitamos `r nrow(ind_orig_sel)` de escenas únicas ALOS PALSAR RTC. Señalamos en este punto un detalle relevante para el análisis hidrológico. Las escenas correspondientes a la porción haitiana del río Artibonito, no las procesamos en este estudio, a efectos de agilizar la producción de resultados. No obstante, dicha tarea nos quedó pendiente para futuras investigaciones.

```{r}
ind_orig_sel_m <- ind_orig_sel %>%
  ggplot +
  geom_sf(alpha = 0.6, fill = 'grey90', color = 'grey20', size = 0.5) +
  geom_sf(data = pais, fill = 'transparent', color = 'black') +
  geom_sf_label(aes(label = sceneName), color = 'red', size = 1.5,
                label.padding = unit(0.1, "lines"), alpha = 0.9) +
  theme_bw() + 
  theme(plot.title = element_text(size = 11)) +
  ggspatial::annotation_scale(style = 'ticks')
```

Usando como referencia el índice de escenas seleccionadas, extrajimos los DEM correspondientes, incluidos en formato GTiff dentro de los archivos comprimidos (`.zip`). Este formato es proporcionado por el Alaska Satellite Facility para minimizar el uso del ancho de banda durante las descargas, lo que resulta beneficioso para el rendimiento de sus servidores. A pesar de estar comprimidos, la descompresión de estos archivos no supone un proceso largo o laborioso.

```{r, eval=F}
zip_path <- 'alos-palsar-dem-rd/'
sapply(ind_orig_sel$fileName, 
       function(x)
         unzip(
           zipfile = paste0(zip_path, x),
           exdir = paste0(zip_path, 'dem'), junkpaths = T,
           files = paste0(gsub('.zip', '', x), '/', gsub('zip', 'dem.tif', x)))
       )
```

Todos los DEM fueron proporcionados por ASF en el sistema de coordenadas Universal Transversal de Mercator (UTM). Sin embargo, los situados al oeste fueron suministrados en el huso 18N. Identificamos estos DEM y los transformamos al huso 19N, que es el que corresponde a nuestra área, con el objetivo de generar un producto continuo. Para realizar esta transformación, empleamos la herramienta `gdalwarp` de la biblioteca GDAL [@gdal2022gdal].

```{r, eval=F}
dems_orig_path <- list.files(path = 'alos-palsar-dem-rd/dem',
                             pattern = '*dem.tif', full.names = T)
crs_18n <- names(which(sapply(dems_orig_path, function(x){
  crs_x <- gdal_crs(x)
  is_z18 <- grepl('zone 18N', crs_x[['wkt']])
})))
sapply(crs_18n, function(x) file.rename(from = x, to = gsub('.tif', '_z18n.tif', x)))
crs_18n_ren <- list.files(path = 'alos-palsar-dem-rd/dem',
                          pattern = 'z18n.tif', full.names = T)
sapply(crs_18n_ren, function(x){
  gdalwarp(
  srcfile = x,
  dstfile = gsub('_z18n.tif', '.tif', x), 
  t_srs = 'EPSG:32619', overwrite = T)})
```

A efectos de eficientizar la manipulación del DEM, creamos un ráster virtual (VRT) usando la herramienta `gdalbuildvrt` de la biblioteca GDAL. Un ráster virtual es básicamente la abstracción de una imagen que se genera *on the fly*, creado a partir de un índice de tamaño pequeño, en formato XML, que apunta a los archivos originales sin moverlos ni alterarlos. Tienen las mismas prestaciones que las imágenes guardadas permanentes guardadas en disco, por lo que con un ráster virtual podemos visualizar un mosaico continuo o realizar análisis intermedios, o evaluar un producto antes de crearlo de forma definitiva. Se trata de un formato muy eficiente que ayuda a ahorrar espacio en disco.

```{r, eval=F}
gdalbuildvrt(gdalfile = dems_orig_path,
             output.vrt = paste0(paste0(zip_path, 'dem'), '/dem_seamless.vrt'),
             resolution = 'highest', r = 'average')
```

Posterioremente, creamos la base de datos y localización de GRASS GIS usando como fuente de extensión y resolución el ráster virtual [@GRASS_GIS_softwarev82]. Decidimos usar GRASS GIS a partir de este punto para prácticamente todas las tareas de análisis geoespacial e hidrológico, pues se trata de un software bastante eficiente en muchos de sus complementos y algoritmos de serie (e.g. rellenado de nulos). Sin embargo, en pasos posteriores, alternamos el flujo de procesamiento con otras herramientas, como WhiteboxTools [@lindsay2018whiteboxtools]. En todo caso, nuestro criterio fue siempre aprovechar al máximo los recursos de hardware y software disponibles para obtener los productos requeridos en el menor tiempo posible.

```{bash, eval=F}
# Usando Bash, desde la ruta ./alos-palsar-dem-rd/dem
grass --text -c dem_seamless.vrt ./grassdata
# Para abrir luego de cerrada: grass grassdata/PERMANENT/
```

Luego creamos una máscara de país en QGIS [@QGIS_software], superponiendo el límite oficial obtenido desde la página de la [Oficina Nacional de Estadística (ONE)](https://www.one.gob.do/), y combinándolo con otras fuentes disponibles en línea, como [GADM](https://gadm.org/), [Humanitarian Data Exchange (OCHA)](https://data.humdata.org/dataset/cod-ab-dom) y [OpenStreetMap](https://www.openstreetmap.org) [@one2023division; @gadm; @ocha2023hdx; @OpenStreetMap]. De la máscara, eliminamos las superficies de máximas de lagos y lagunas no artificiales, pues nos interesa procesar las cuencas endorreicas que drenan hacia ellos. No obstante, los embalses no los incluimos en dicha superficie, dado que necesitamos construir la jerarquía de red ignorando su presencia, es decir, asumiendo como continuos todos los cursos fluviales. Sobre esta máscara, creamos un área de influencia, para recortar el DEM con un cierto "acolchado" que nos permitiera análizar sin dificultades las áreas costeras y de frontera. La creación de esta máscara fue el único paso que realizamos de forma semimanual, pues el resto del flujo de procesamiento lo realizamos con algoritmo automáticos.

Posteriormente, importamos la máscara generada a la base de datos de GRASS y la aplicamos. GRASS opera de forma eficiente, circunscribiendo la aplicación de los algoritmos al área definida como máscara. Las áreas fuera de ésta son excluidas, eficientizando los recursos y evitando malgastar tiempo de CPU en áreas que ajenas al proyecto.

```{bash, eval=F}
# Importar máscara
v.import input=mascara-1km.gpkg output=mascara_1km

# Fijar máscara
r.mask -r
r.mask vector=mascara_1km

# Ver ambiente
g.gisenv
## GISDBASE=/media/jose/datos/alos-palsar-dem-rd/dem
## LOCATION_NAME=grassdata
## MAPSET=PERMANENT
## GUI=text
## PID=1632142
```

Importamos el ráster virtual a la base de datos de GRASS GIS con la herramienta `r.import`. Con este paso generamos un mapa ráster dentro de la base de datos GRASS GIS, el cual es una realización con celdas manipulables y a la que le podemos aplicar algoritmos ráster de nuestra preferencia.

```{bash, eval=F}
# Importar DEM a región de GRASS
time r.import --overwrite input=dem_seamless.vrt output=dem
## real 

# Ver en lista (q para salir)
g.list type=raster
```

```{r demsinprocesar, echo=F, fig.cap='DEM sin procesar, representado como relieve sombreado. Nótesense los píxeles sin datos, destacados en color rojo (Los Patos-Ojeda-Paraíso, provincia Barahona, sudoeste de República Dominicana)'}
knitr::include_graphics("out/dem-sin-procesar.jpg")
```

A continuación, rellenamos las celdas con valor nulo (sin datos) por medio del eficiente complemento de GRASS `r.fill.nulls`. Lo configuramos para rellenar píxeles nulos usando interpolación *spline* bilineal con regularización Tykhonov (*spline* es un método de descomposición de curvas en porciones descritas por polinomios).

```{bash, eval=F}
# Rellenar vacíos
time r.fillnulls --overwrite --verbose \
  input=dem method="bilinear" \
  tension=40 smooth=0.1 edge=3 npmin=600 segmax=300 lambda=0.01 \
  output=dem_relleno
# Enviar mensaje al finalizar (ejecutar conjuntamente con anterior)
echo "Job finished" | mail -s "Job finished" USUARIO@MAIL
## real 10m11.925s
```

```{r demrelleno, echo=F, fig.cap='DEM sin procesar, representado como relieve sombreado. Los píxeles sin datos fueron eliminados (Los Patos-Ojeda-Paraíso, provincia Barahona, sudoeste de República Dominicana)'}
knitr::include_graphics("out/dem-relleno.jpg")
```

En el siguiente paso suavizamos el DEM preservando morfologías. Para esto usamos la herramienta *FeaturePreservingSmoothing* de WhiteboxTools, la cual reduce la rugosidad generada por el ruido en el DEM [@lindsay2019; @lindsay2018whiteboxtools]. Para aplicar esta herramienta, primero exportamos el DEM desde la base de datos de GRASS GIS a archivo GeoTIFF, y posteriormente aplicamos el suavizado. Finalmente, importamos el DEM suavizado nuevamente a la base de datos de GRASS GIS para continuar el procesamiento en dicha aplicación.

```{bash, eval=F}
# Exportar a GTiff con compresión LZW
time r.out.gdal --overwrite --verbose createopt="COMPRESS=LZW,BIGTIFF=YES" \
  input=dem_relleno \
  format=GTiff type=Float64 output=dem_relleno.tif
# Enviar mensaje al finalizar (ejecutar conjuntamente con anterior)
echo "Job finished" | mail -s "Job finished" USUARIO@MAIL
## real	0m58.924s

# Comenzó a 23.20 de 22 de abril
time ~/WhiteboxTools_linux_amd64/WBT/whitebox_tools \
  --wd='/media/jose/datos/alos-palsar-dem-rd/dem/' \
  --filter=25 --norm_diff=45 --num_iter=5 \
  --run=FeaturePreservingSmoothing --input='dem_relleno.tif' \
  --output='dem_relleno_suavizado.tif' -v
# Enviar mensaje al finalizar (ejecutar conjuntamente con anterior)
echo "Job finished" | mail -s "Job finished" USUARIO@MAIL
## real	9min46.103s
```

```{r demsuavizado, echo=F, fig.cap='DEM suavizado, representado como relieve sombreado. Nótese la conservación de las morfologías principales y la eliminación del ruido sobre éstas (Los Patos-Ojeda-Paraíso, provincia Barahona, sudoeste de República Dominicana)'}
knitr::include_graphics("out/dem-suavizado.jpg")
```

```{bash, eval=F}
time r.import input=dem_relleno_suavizado.tif output=dem_suavizado
echo "Job finished" | mail -s "Job finished" USUARIO@MAIL
## real	0m21.593s
```

A continuación, usamos el ráster de altura de geoide de La Española a 1 minuto de resolución (EGM2008) para obtener alturas pseudo-ortométricas, por medio de una suma algebraica simple de este ráster y el DEM suavizado en GRASS GIS con la herramienta `r.mapcalc`. Sin embargo, previamente fue necesario aumentar la resolución del ráster de altura del geoide antes de realizar la suma. Para esto, usamos `r.resamp.rst` (evaluamos una segunda alternativa con el complemento `r.resamp.interp` y, aunque realizó el trabajo eficientemente, eliminó muchas áreas limítrofes, por lo que preferimos no utilizarlo).

```{bash, eval=F}
# Importar DEM a región de GRASS
r.import --overwrite input=egm2008-1_espanola.tif output=egm2008_1min

# Ver en lista (q para salir)
g.list type=raster

# Ver atributos de la región
g.region -p

# Alternativa 1. Usando r.resamp.rst. Más eficiente y precisa
# Fijar la región al geoide importado
g.region raster=egm2008_1min -ap
# Realizar la interpolación
r.resamp.rst --overwrite input=egm2008_1min ew_res=50 ns_res=50 elevation=egm2008_hires
echo "Job finished" | mail -s "Job finished" USUARIO@MAIL
## real	
# Fijar región a nuevo geoide
g.region raster=egm2008_hires -ap

# Alternativa 2. Usando r.resamp.interp. También eficiente, pero eliminar áreas de borde
# g.region res=50 -ap
# r.resamp.interp --overwrite input=egm2008_1min \
#  output=egm2008_hires method=bilinear

# Exportar para explorar visualmente
# r.out.gdal --overwrite --verbose createopt="COMPRESS=LZW" \
#  input=egm2008_hires \
#  format=GTiff type=Float64 output=egm2008_hires.tif

# Volver a resolución de DEM rellenado y suavizado
g.region raster=dem_suavizado -ap

# Aplicar álgebra de mapas
r.mapcalc --overwrite "dem_pseudo_ortometrico = dem_suavizado - egm2008_hires"

#Estadísticos univariados
r.univar dem_pseudo_ortometrico
# n: 306462417
# minimum: -51.4456
# maximum: 3102.34
# range: 3153.79
# mean: 403.703
# mean of absolute values: 403.858
# standard deviation: 487.27
# variance: 237432
# variation coefficient: 120.7 %
# sum: 123719658638.311
```

El resumen estadístico proporcionado por la herramienta `r.univar` de GRASS GIS, usando la máscara ajustada a los límites costeros e internacional del país, informa que la elevación mínima es -51.5 m, mientras que la máxima es 3102.34 m, para un rango de casi 3154 m. El valor mínimo probablemente no está bien recogido, debido a que la máscara empleada podría estar eliminando elevaciones muy bajas en el área de la Hoya de Enriquillo. La elevación media, considerando tanto los negativos como los positivos, es de aproximadamente 404 m, con desviación estándar de 487 m y coeficiente de variación de 121%. Remarcamos que, aunque ASF advierte de no usar este modelo para fines de elevación, el valor máximo se ajusta bastante a la elevación máxima conocida en República Dominicana, que es el pico Duarte [@ign2022medicion].

```{r alturasgeoideelipsoide, echo=F, fig.cap='Alturas respecto de geoide EGM08 ($\\sim$ortométrica) y sobre elipsoide WGS84, de un transecto descendente desde Bahoruco Oriental al Mar Caribe (Los Patos-Ojeda-Paraíso, provincia Barahona, sudoeste de República Dominicana)'}
knitr::include_graphics("out/perfiles-dem/los-patos.png")
```

A continuación, efectuamos el procedimiento de tallado o grabado de una red preexistente sobre el DEM, conocido como *stream burning* [@lindsay2016]. Con este procedimiento, logramos que los píxeles del DEM intersectados con el vectorial de la red preexistente, adquieran un valor muy bajo respecto de su entorno, para asegurar que los algoritmos automáticos de análisis hidrológico dirijan el flujo a través de los lechos de ríos establecidos. El tallado es particularmente útil, incluso esencial, en áreas planas, ya que ayuda a los algoritmos autómáticos a producir redes hidrográficas más realistas y topológicamente correctas. Sin embargo, su aplicación de requiere de una cuidadosa selección de la red preexistente a tallar. Para crearla, usamos una red de drenaje de cursos fluviales seleccionados, que incluyó sólo los de gran longitud, comúnmente ríos permamentes, de lecho ancho y claramente establecidos. Nos apoyamos en imágenes satelitales [@googlemaps] y, ocasionalmente, en el MTN-50K [@icm1989serie]. Complementamos con @OpenStreetMap, ya que este servicio provee información vectorial de fácil acceso y precisa. El resultado consistió en una red de cursos largos seleccionados de República Dominicana, representada por los ríos Artibonito, Yaque del Norte, Yuna, Yaque del Sur, varios ríos del extremo meridional de la cordillera Central y del borde sudoriental del país, así como algunos ríos seleccionados de la cordillera Septentrional.

```{r redcursoslargos, echo=F, fig.cap='Mapa de la red de cursos largos creada para el estudio a partir de varias fuentes (más detalles, en el texto).'}
knitr::include_graphics("out/red-cursos-largos.jpg")
```

Nuestra de red cursos largos contiene varios ríos que atraviesan amplios valles y karsts, por lo son comunes los tramos que cruzan zonas complicadas para la conducción del flujo donde probablemente el error posicional de las líneas es mayor. Cabe también señalar que, para asegurar la continuidad topológica de la red, dimos un tratamiento especial a los ríos que llenan embalses, los cuales representamos por medio trazados históricos obtenidos del MTN-50K, omitiendo así la presencia de los embalses.

```{bash, eval=F}
# Importar red a GRASS
v.import --overwrite input=red_mtn50k_cleaned_largos.gpkg \
  output=red_mtn50k_cleaned_largos
# Ver mapa importado en lista (q para salir)
g.list type=vector
# Calcular y pasar a archivo, la longitud de cursos
# y número de segmentos (ejecutar en casos de actualización)
v.to.db -p option=length map=red_mtn50k_cleaned_largos > \ 
  stats_length_red_mtn50k_cleaned_largos.txt
```

```{r, message=F, warning=F}
stats_red_mtn50k_largos <- read_delim(
  paste0(dem_proc_dir,
         'stats_length_red_mtn50k_cleaned_largos.txt'),
  progress = F, show_col_types = F)
n_seg_red_mtn50k_largos <- stats_red_mtn50k_largos %>%
  filter(!cat==-1) %>% nrow
length_mtn50k_largos <- stats_red_mtn50k_largos %>%
  filter(!cat==-1) %>% pull(length) %>% sum/1000
```

Finalmente, importamos nuestra red de cursos largos a la base de datos de GRASS GIS y generamos estadísticas básicas. Se trata de una red compuesta por **`r format(n_seg_red_mtn50k_largos, scientific=F)` segmentos** que suman un total de **`r format(length_mtn50k_largos, scientific=F, digits=6)` kilómetros** de longitud. Cabe señalar que esta red no tiene valor hidrográfico, pues, como indicamos, ignora los lagos para garantizar la integridad topológica. Desaconsejamos su uso para otro fin que no sea el grabado de un DEM.

El siguiente paso consistió en realizar el *stream burning* (tallado) de la red de cursos largos con distintos algoritmos sobre el DEM. Probamos las funciones `r.carve` y `r.mapcalc` (álgebra de mapas) de GRASS GIS, y `FillBurn` de WhiteboxTools [@GRASS_GIS_software; @lindsay2018whiteboxtools]. Sin embargo, es importante señalar que, dependiendo del algoritmo usado, el grabado modifica de forma diferente el DEM. Además, algunos algoritmos modifican no solamente los píxeles intersectados sino también otros píxeles, incluso pueden llegar a cambiar los valores en el DEM completo. Nosotros priorizamos un método de grabado que fuese efectivo pero que a la vez produjese la mínima alteración sobre el DEM.

Comenzamos con `r.carve`, una herramienta diseñada para grabar el DEM sin modificarlo sustancialmente, permitiendo al mismo tiempo configurar la profundidad y la anchura del grabado [@petrasova2011geoinformation; @grassdev2022rcarve]. Por defecto, la anchura de lecho es equivalente a la resolución del DEM. La profundidad puede definirse por el usuario, para lo cual nosotros establecimos 100 metros. Pudimos tallar la red de cursos largos sobre el DEM con esta herramienta, generando un resultado que consideramos bueno, aunque el proceso ocupó más de 1 hora de tiempo de cómputo. Esta alternativa es recomendada si resultase imprescindible conservar las propiedades topográficas en el DEM, pero debe tenerse en cuenta que su rendimiento es muy bajo. En los casos en los que se use un DEM de resolución baja, se recomienda usar esta alternativa. Sin embargo, a nosotros no nos resultó apropiado este método por razones de rendimiento, que explicamos a continuación. Para evaluar el rendimiento del DEM tallado, realizábamos un procesamiento hidrológico abreviado (generación de la acumulación de flujo y extracción de la red con `r.watershed`); si los productos generados (e.g. red hidrográfica) no nos parecían idóneos, nos veíamos en la necesidad iterar, editando la red y aplicando el tallado nuevamente. Dado que el complemento `r.carve` era poco eficiente, preferimos buscar otras opciones de tallado.

```{bash, eval=F}
# Limpiar red manualmente en QGIS
# Para mejorar la topología, se puede aplicar v.clean directamente en QGIS

# Tallar red de cursos largos
time r.carve --overwrite --verbose raster=dem_pseudo_ortometrico \
  vector=red_mtn50k_cleaned_largos output=dem_tallado depth=100
echo "r.carve finalizado" | mail -s "r.carve finalizado" USUARIO@MAIL
## real	97m3.970s
```

Posteriormente, probamos el tallado usando álgebra de mapas con herramienta `r.mapcalc` de GRASS GIS [@GRASS_GIS_software; @grassdev2022rmapcalc; @shapiro1994rmapcalc; @larson1991performing]. Para tallar con álgebra de mapas, primero normalizamos el DEM, generamos una capa booleana ráster con la red de cursos largos, la restamos al DEM normalizado y luego, para restablecer los valores originales fuera de las áreas talladas, multiplicamos el ráster resultante de la resta nuevamente por el rango del DEM (máximo - mínimo). El resultado es un DEM tallado, en el que sólo los píxeles por donde circula la red quedaron con una profundidad equivalente al rango.

```{r, eval=F}
# Limpiar red manualmente en QGIS
# Para mejorar la topología, se puede aplicar v.clean directamente en QGIS

# Tallar
# Rasterizar red (los píxeles de la red valdrán 1, el resto, nulo)
v.to.rast --overwrite input=red_mtn50k_cleaned_largos type=line use=val \
  output=red_mtn50k_cleaned_largos
# Convertir nulos a cero
r.null map=red_mtn50k_cleaned_largos null=0
# Determinar estadísticas univariantes del DEM
r.univar map=dem_pseudo_ortometrico
# minimum: -51.4456
# maximum: 3102.34

# Aplicar normalización y resta
r.mapcalc --overwrite << EOF
eval(stddem = (dem_pseudo_ortometrico - -51.4456) / (3102.34 - -51.4456), \
     stddemburn = stddem - red_mtn50k_cleaned_largos)
dem_tallado = (stddemburn * (3102.34 - -51.4456)) - 51.4456
# dem_tallado = stddemburn * dem_pseudo_ortometrico # Alternativa
EOF
echo "Tallado finalizado" | mail -s "Mensaje sobre tallado" USUARIO@MAIL
```

```{r demtallado, echo=F, fig.cap='DEM sin aplicación de hidrografía (A), y con aplicación de hidrografía seleccionada (B). El DEM se representa como relieve sombreado y la aplicación se denota como un grabado oscurecido (cañón del río Payabo, Los Haitises, y río Yuna (proximidades de Arenoso, nordeste de República Dominicana)'}
knitr::include_graphics("out/dem-sin-tallar-tallado.png")
```

Como última alternativa de procesamiento, probamos la herramienta `FillBurn`, basada en @saunders2000 e implementada por @lindsay2016 en de WBT. `FillBurn` realiza dos modificaciones a la vez sobre el DEM; por una parte, graba la red, usando una profundidad por defecto y, por otro, rellena las depresiones. La herramienta mostró mejor rendimiento que la de GRASS GIS en cuanto a tiempo de cómputo. Tras tallar la red evaluamos el DEM resultante, y comprobamos que **resultó ser muy diferente al original, especialmente en las áreas con depresiones**. Por esta razón, descartamos este DEM y elegimos usar el tallado por medio de álgebra de mapas (`r.mapcalc`) con GRASS GIS en los siguientes pasos de nuestro flujo de trabajo.

```{bash, eval=F}
# Exportar dem_pseudo_ortometrico a GTiff con compresión LZW
time r.out.gdal --overwrite --verbose createopt="COMPRESS=LZW,BIGTIFF=YES" \
 input=dem_pseudo_ortometrico \
 format=GTiff type=Float64 output=dem_pseudo_ortometrico.tif
echo "Job finished" | mail -s "Job finished" USUARIO@MAIL
## real 1m0.248s

# Exportar red_mtn50k_cleaned_largos.gpkg a shapefile
ogr2ogr(
  src_datasource_name = '/media/jose/datos/alos-palsar-dem-rd/dem/red_mtn50k_cleaned_largos.gpkg',
  dst_datasource_name = '/media/jose/datos/alos-palsar-dem-rd/dem/red_mtn50k_cleaned_largos.shp',
  verbose=TRUE)

# Tallar con WBT
time ~/WhiteboxTools_linux_amd64/WBT/whitebox_tools \
  --wd='/media/jose/datos/alos-palsar-dem-rd/dem/' \
  --run=FillBurn --dem='dem_pseudo_ortometrico.tif' \
  --streams=red_mtn50k_cleaned.shp --output='dem_tallado.tif' -v
echo "Job finished" | mail -s "Job finished" USUARIO@MAIL
## real	9m21.980s
# Importar a GRASS GIS
time r.import --overwrite input=dem_tallado.tif output=dem_tallado
echo "Job finished" | mail -s "Job finished" USUARIO@MAIL
## real	0m38.519s
```

A continuación, aplicamos algoritmos de grabado de depresiones ... ... ...

### Procesamiento de hidrología computacional

El próximo paso consistió en 



## Informe de la sesión de R {.unnumbered}

```{r}
sessionInfo()
```
